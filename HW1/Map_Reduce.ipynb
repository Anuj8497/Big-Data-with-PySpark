{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following code implements the process of Map-Reduce. \n",
    "* To execute, just run the cells in the order in which they are written\n",
    "* Finally this python notebook outputs a csv file containing words and number of times they occured. \n",
    "* Code is written according to the instructions and the flowchart given in the homework document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing required libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import operator\n",
    "import string\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function takes in the raw text file and it converts upper case characters to lowercase, eliminates digits, also removes punctuations and special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(x):\n",
    "    f = open(x,'r') #Opening the file object\n",
    "    text = f.read() # Reading from the file object\n",
    "    a = ''.join([i for i in text if not i.isdigit()]) # Removing all the numbers from text\n",
    "    a = text.lower() # Converting to lower case\n",
    "    b = re.sub(r\"[^a-z\\s]+\",' ',a) # Removing punctuations\n",
    "    text = \"\".join([s for s in b.strip().splitlines(True) if s.strip()]) # Removing all blank lines\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean = data_clean(r'C:\\Users\\anuj8\\data.txt') #Calling data clean function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function takes in clean text as input, generates two partitions, one with first 5000 lines and other with rest text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(y):\n",
    "    lines = y.splitlines()   \n",
    "    split = lines[5001] # Getting the line number 5001\n",
    "    res = y.partition(split)[0] # Call the inbuilt pandas partition function and take the first half i.e. first 5000 lines\n",
    "    result = res.split()\n",
    "    split = lines[5000] # Getting line number 5000\n",
    "    res1 = y.partition(split)[2] # Call the inbuilt pandas partition function and take the second half i.e. rest of the line after 5000 \n",
    "    result1 = res1.split()\n",
    "    return(result,result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first,first1 = data_split(clean) # Calling split function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function takes in the text and geneartes a set of key value pairs <word,1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper1(list):\n",
    "    mydict = [] #Initializing dictionary\n",
    "    for x in list:\n",
    "        key_value = [x,1] \n",
    "        mydict.append(key_value) #Inserting key value pairs in the dictionary\n",
    "    temp = pd.DataFrame(mydict,columns = ['word','count'])  \n",
    "    return (temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = mapper1(first) # Calling mapper function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function takes in the text and geneartes a set of key value pairs <word,1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper2(list):\n",
    "    mydict = [] #Initializing dictionary\n",
    "    for x in list:\n",
    "        key_value = [x,1] # Generating key value pairs\n",
    "        mydict.append(key_value) #Inserting key value pairs in the dictionary\n",
    "    temp = pd.DataFrame(mydict,columns = ['word','count'])  \n",
    "    return (temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_1 = mapper2(first1) # Calling mapper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([ans,ans_1]) #Combining outputs of mapper function 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function performs sorting on the words in an ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting(data):\n",
    "    test = data.sort_values('word',axis = 0,ascending = True,kind = 'quicksort',ignore_index = True)\n",
    "    return(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = sorting(combined) # Calling sorting function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function perfroms partition i.e. All the words starting from a-m are stored in one set and the rest in other set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_1(ans):\n",
    "    for i in ans.index:\n",
    "        if (ans.loc[i]['word'][0] == 'n'): #This line of code checks for the word begining with letter n appears for the first time.\n",
    "            break\n",
    "    first_set = ans[0:i] # words starting with a-m in the first set\n",
    "    second_set = ans[i:] # words starting with n-z in the first set\n",
    "    return(first_set,second_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_set,second_set = partition_1(ans) #Calling partition function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** This function takes key value pairs and does the word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer1(first_set):\n",
    "    return(first_set['word'].value_counts())  #Aggregating similiar words together and counting them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function takes key value pairs and does the word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer2(second_set):\n",
    "    return(second_set['word'].value_counts()) #Aggregating similar words together and counting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = reducer1(first_set) # Calling reducer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "set2 = reducer2(second_set) # Calling reducer function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function takes in the aggregated word count pairs and generates a final csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(set1,set2):\n",
    "    set1_1 = pd.DataFrame({'Word':set1.index,'count':set1.values}) #COnverting aggregated key value pairs into dataframe\n",
    "    set2_2 = pd.DataFrame({'Word':set2.index,'count':set2.values}) #COnverting aggregated key value pairs into dataframe\n",
    "    result = pd.concat([set1_1, set2_2], axis=0) #Combining the two sets\n",
    "    result = result.sort_values('Word',axis = 0,ascending = True,kind = 'quicksort',ignore_index = True)\n",
    "    result.to_csv('final_ou.csv',index = False) # Writing the final output to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(set1,set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
